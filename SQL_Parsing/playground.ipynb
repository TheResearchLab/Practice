{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f98cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlglot in c:\\users\\aaron\\documents\\repos\\practice\\practice_env\\lib\\site-packages (27.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlglot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62555486",
   "metadata": {},
   "source": [
    "# Evaluation steps\n",
    "\n",
    " \n",
    "\n",
    "### Model Eval\n",
    "   - Unions\n",
    "\n",
    "   - CTEs & Recursive CTEs\n",
    "\n",
    "   - Time travel syntax\n",
    "\n",
    "   - Sub-queries\n",
    "\n",
    " \n",
    "\n",
    "### Column Eval\n",
    "  - Aliases\n",
    "\n",
    "  - \"SELECT *\"\n",
    "\n",
    "  - Calculated/Multi-column fields\n",
    "\n",
    "  - Window Functions\n",
    "\n",
    "    - Qualified Column Refs\n",
    "\n",
    " \n",
    "\n",
    "### Other\n",
    "\n",
    "   - Masking salt key in output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffc193",
   "metadata": {},
   "source": [
    "# Models Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bac002",
   "metadata": {},
   "source": [
    "## Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc0e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake tables found:\n",
      "  - ECOMMERCE_DB.SALES.ONLINE_ORDERS\n",
      "  - ECOMMERCE_DB.SALES.RETAIL_SALES\n",
      "  - MOBILE_APP_DB.TRANSACTIONS.MOBILE_TRANSACTIONS\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "from sqlglot import expressions as exp\n",
    "\n",
    "\"\"\"\n",
    "Can I assume all snowflake compiled models will be formatted as db.schema.tbl? I think?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Example UNION query in Snowflake syntax (no quotes)\n",
    "union_query = \"\"\"\n",
    "SELECT CUSTOMER_ID, ORDER_DATE, 'online' AS CHANNEL\n",
    "FROM ECOMMERCE_DB.SALES.ONLINE_ORDERS\n",
    "WHERE ORDER_DATE >= '2024-01-01'\n",
    "UNION ALL\n",
    "SELECT CUSTOMER_ID, PURCHASE_DATE AS ORDER_DATE, 'retail' AS CHANNEL\n",
    "FROM ECOMMERCE_DB.SALES.RETAIL_SALES\n",
    "WHERE PURCHASE_DATE >= '2024-01-01'\n",
    "UNION\n",
    "SELECT CUST_ID AS CUSTOMER_ID, TRANSACTION_DATE AS ORDER_DATE, 'mobile' AS CHANNEL\n",
    "FROM MOBILE_APP_DB.TRANSACTIONS.MOBILE_TRANSACTIONS\n",
    "WHERE TRANSACTION_DATE >= '2024-01-01'\n",
    "\"\"\"\n",
    "\n",
    "def extract_snowflake_tables(sql_query):\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    tables = set()\n",
    "    for node in parsed.walk():\n",
    "        if isinstance(node, exp.Table):\n",
    "            db = node.catalog or \"\"\n",
    "            schema = node.db or \"\"\n",
    "            name = node.name\n",
    "            # Build full table name: DATABASE.SCHEMA.TABLE (no quotes)\n",
    "            if db and schema:\n",
    "                full_name = f\"{db}.{schema}.{name}\"\n",
    "            elif schema:\n",
    "                full_name = f\"{schema}.{name}\"\n",
    "            else:\n",
    "                full_name = name\n",
    "            tables.add(full_name)\n",
    "    return sorted(tables)\n",
    "\n",
    "# Test extraction\n",
    "tables = extract_snowflake_tables(union_query)\n",
    "print(\"Snowflake tables found:\")\n",
    "for t in tables:\n",
    "    print(f\"  - {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587a46f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  - db1.schema1.tableA\n",
      "  - db2.schema2.tableB\n",
      "\n",
      "Test case 2:\n",
      "  - analytics.inactive_users\n",
      "  - analytics.orders\n",
      "  - analytics.users\n",
      "\n",
      "Test case 3:\n",
      "  - marketing.leads\n",
      "  - recent_orders\n",
      "  - sales.customers\n",
      "  - sales.orders\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    # 1. Simple UNION with single tables\n",
    "    \"\"\"\n",
    "    SELECT id FROM db1.schema1.tableA\n",
    "    UNION\n",
    "    SELECT id FROM db2.schema2.tableB\n",
    "    \"\"\",\n",
    "\n",
    "    # 2. UNION ALL with JOIN and subquery\n",
    "    \"\"\"\n",
    "    SELECT u.user_id, o.order_id\n",
    "    FROM analytics.users u\n",
    "    JOIN analytics.orders o ON u.user_id = o.user_id\n",
    "    UNION ALL\n",
    "    SELECT user_id, NULL\n",
    "    FROM analytics.inactive_users\n",
    "    WHERE last_login < '2024-01-01'\n",
    "    \"\"\",\n",
    "\n",
    "    # 3. UNION with nested SELECT and CTE\n",
    "    \"\"\"\n",
    "    WITH recent_orders AS (\n",
    "        SELECT order_id, customer_id\n",
    "        FROM sales.orders\n",
    "        WHERE order_date > '2025-01-01'\n",
    "    )\n",
    "    SELECT customer_id FROM recent_orders\n",
    "    UNION\n",
    "    SELECT customer_id FROM sales.customers\n",
    "    WHERE signup_date > '2025-01-01'\n",
    "    UNION ALL\n",
    "    SELECT customer_id FROM marketing.leads\n",
    "    WHERE source = 'web'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    tables = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    for t in tables:\n",
    "        print(f\"  - {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dfe4d",
   "metadata": {},
   "source": [
    "## CTEs and Recursive CTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d70fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  - db1.schema1.tableA\n",
      "  - db2.schema2.tableB\n",
      "\n",
      "Test case 2:\n",
      "  - analytics.inactive_users\n",
      "  - analytics.orders\n",
      "  - analytics.users\n",
      "\n",
      "Test case 3:\n",
      "  - marketing.leads\n",
      "  - recent_orders\n",
      "  - sales.customers\n",
      "  - sales.orders\n",
      "\n",
      "Test case 4:\n",
      "  - active_customers\n",
      "  - crm_db.marketing.leads\n",
      "  - crm_db.sales.customers\n",
      "  - crm_db.sales.orders\n",
      "  - crm_db.sales.products\n",
      "  - crm_db.sales.returns\n",
      "  - recent_orders\n"
     ]
    }
   ],
   "source": [
    "test_queries.append(\n",
    "    \"\"\"\n",
    "    WITH active_customers AS (\n",
    "        SELECT customer_id\n",
    "        FROM crm_db.sales.customers\n",
    "        WHERE status = 'active'\n",
    "    ),\n",
    "    recent_orders AS (\n",
    "        SELECT order_id, customer_id\n",
    "        FROM crm_db.sales.orders\n",
    "        WHERE order_date > '2025-01-01'\n",
    "    ),\n",
    "    top_products AS (\n",
    "        SELECT product_id\n",
    "        FROM crm_db.sales.products\n",
    "        WHERE rating > 4.5\n",
    "    )\n",
    "    SELECT ac.customer_id, ro.order_id\n",
    "    FROM active_customers ac\n",
    "    JOIN recent_orders ro ON ac.customer_id = ro.customer_id\n",
    "    UNION\n",
    "    SELECT customer_id, NULL\n",
    "    FROM crm_db.marketing.leads\n",
    "    WHERE source = 'web'\n",
    "    UNION ALL\n",
    "    SELECT NULL, order_id\n",
    "    FROM recent_orders\n",
    "    WHERE order_id NOT IN (SELECT order_id FROM crm_db.sales.returns)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    tables = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    for t in tables:\n",
    "        print(f\"  - {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17aafc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  - db1.schema1.tableA\n",
      "  - db2.schema2.tableB\n",
      "\n",
      "Test case 2:\n",
      "  - analytics.inactive_users\n",
      "  - analytics.orders\n",
      "  - analytics.users\n",
      "\n",
      "Test case 3:\n",
      "  - marketing.leads\n",
      "  - recent_orders\n",
      "  - sales.customers\n",
      "  - sales.orders\n",
      "\n",
      "Test case 4:\n",
      "  - active_customers\n",
      "  - crm_db.marketing.leads\n",
      "  - crm_db.sales.customers\n",
      "  - crm_db.sales.orders\n",
      "  - crm_db.sales.products\n",
      "  - crm_db.sales.returns\n",
      "  - recent_orders\n",
      "\n",
      "Test case 5:\n",
      "  - __dbt__cte__dummy_data\n",
      "  - dummy_schema.dummy_dim\n",
      "  - dummy_schema.dummy_table\n",
      "  - get_dummy_data\n"
     ]
    }
   ],
   "source": [
    "test_queries.append(\n",
    "    \"\"\"\n",
    "    WITH __dbt__cte__dummy_data AS (\n",
    "        SELECT\n",
    "            upper(nullif(v:DUMMY_VER_NAME::STRING,'')) AS dummy_ver_name,\n",
    "            upper(nullif(v:DUMMY_POP_NAME::STRING,'')) AS dummy_pop_name,\n",
    "            upper(nullif(v:DUMMY_LEVEL_CD::STRING,'')) AS dummy_level_cd,\n",
    "            upper(nullif(v:DUMMY_VAR_NAME::STRING,'')) AS dummy_var_name,\n",
    "            nullif(v:DUMMY_COEF::STRING,'')::NUMBER(8,3) AS dummy_coef\n",
    "        FROM dummy_schema.dummy_table\n",
    "    ),\n",
    "    get_dummy_data AS (\n",
    "        SELECT\n",
    "            dummy_ver_name,\n",
    "            dummy_pop_name,\n",
    "            dummy_level_cd,\n",
    "            dummy_var_name,\n",
    "            dummy_coef\n",
    "        FROM __dbt__cte__dummy_data\n",
    "    )\n",
    "    SELECT\n",
    "        COALESCE(gd.dummy_ver_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_pop_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_level_cd::VARCHAR, '') || '~' || COALESCE(gd.dummy_var_name::VARCHAR, '') AS dummy_id,\n",
    "        dd.dummy_key,\n",
    "        gd.dummy_ver_name,\n",
    "        gd.dummy_pop_name,\n",
    "        gd.dummy_level_cd,\n",
    "        gd.dummy_var_name,\n",
    "        gd.dummy_coef\n",
    "    FROM get_dummy_data gd\n",
    "    INNER JOIN dummy_schema.dummy_dim dd ON gd.dummy_ver_name = dd.dummy_ver_name\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    tables = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    for t in tables:\n",
    "        print(f\"  - {t}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53c31d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  Physical tables:\n",
      "    - db1.schema1.tableA\n",
      "    - db2.schema2.tableB\n",
      "  CTE names:\n",
      "\n",
      "Test case 2:\n",
      "  Physical tables:\n",
      "    - analytics.inactive_users\n",
      "    - analytics.orders\n",
      "    - analytics.users\n",
      "  CTE names:\n",
      "\n",
      "Test case 3:\n",
      "  Physical tables:\n",
      "    - marketing.leads\n",
      "    - sales.customers\n",
      "    - sales.orders\n",
      "  CTE names:\n",
      "    - recent_orders\n",
      "\n",
      "Test case 4:\n",
      "  Physical tables:\n",
      "    - crm_db.marketing.leads\n",
      "    - crm_db.sales.customers\n",
      "    - crm_db.sales.orders\n",
      "    - crm_db.sales.products\n",
      "    - crm_db.sales.returns\n",
      "  CTE names:\n",
      "    - active_customers\n",
      "    - recent_orders\n",
      "    - top_products\n",
      "\n",
      "Test case 5:\n",
      "  Physical tables:\n",
      "    - dummy_schema.dummy_dim\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n"
     ]
    }
   ],
   "source": [
    "def extract_snowflake_tables(sql_query):\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    tables = set()\n",
    "    cte_names = set()\n",
    "\n",
    "    # Collect CTE names\n",
    "    for node in parsed.find_all(exp.CTE):\n",
    "        if node.alias:\n",
    "            cte_names.add(node.alias)\n",
    "\n",
    "    # Collect all table references\n",
    "    for node in parsed.walk():\n",
    "        if isinstance(node, exp.Table):\n",
    "            db = node.catalog or \"\"\n",
    "            schema = node.db or \"\"\n",
    "            name = node.name\n",
    "            if db and schema:\n",
    "                full_name = f\"{db}.{schema}.{name}\"\n",
    "            elif schema:\n",
    "                full_name = f\"{schema}.{name}\"\n",
    "            else:\n",
    "                full_name = name\n",
    "            tables.add(full_name)\n",
    "\n",
    "    # Separate physical tables from CTEs\n",
    "    physical_tables = [t for t in tables if t not in cte_names]\n",
    "    return sorted(physical_tables), sorted(cte_names)\n",
    "\n",
    "\n",
    "\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    physical_tables, cte_names = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    print(\"  Physical tables:\")\n",
    "    for t in physical_tables:\n",
    "        print(f\"    - {t}\")\n",
    "    print(\"  CTE names:\")\n",
    "    for c in cte_names:\n",
    "        print(f\"    - {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06db9a4",
   "metadata": {},
   "source": [
    "## Timestamp Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22cb355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  Physical tables:\n",
      "    - db1.schema1.tableA\n",
      "    - db2.schema2.tableB\n",
      "  CTE names:\n",
      "\n",
      "Test case 2:\n",
      "  Physical tables:\n",
      "    - analytics.inactive_users\n",
      "    - analytics.orders\n",
      "    - analytics.users\n",
      "  CTE names:\n",
      "\n",
      "Test case 3:\n",
      "  Physical tables:\n",
      "    - marketing.leads\n",
      "    - sales.customers\n",
      "    - sales.orders\n",
      "  CTE names:\n",
      "    - recent_orders\n",
      "\n",
      "Test case 4:\n",
      "  Physical tables:\n",
      "    - crm_db.marketing.leads\n",
      "    - crm_db.sales.customers\n",
      "    - crm_db.sales.orders\n",
      "    - crm_db.sales.products\n",
      "    - crm_db.sales.returns\n",
      "  CTE names:\n",
      "    - active_customers\n",
      "    - recent_orders\n",
      "    - top_products\n",
      "\n",
      "Test case 5:\n",
      "  Physical tables:\n",
      "    - dummy_schema.dummy_dim\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n",
      "\n",
      "Test case 6:\n",
      "  Physical tables:\n",
      "    - dummy_schema.dummy_dim\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n"
     ]
    }
   ],
   "source": [
    "test_queries.append(\n",
    "    \"\"\"\n",
    "    WITH __dbt__cte__dummy_data AS (\n",
    "        SELECT\n",
    "            upper(nullif(v:DUMMY_VER_NAME::STRING,'')) AS dummy_ver_name,\n",
    "            upper(nullif(v:DUMMY_POP_NAME::STRING,'')) AS dummy_pop_name,\n",
    "            upper(nullif(v:DUMMY_LEVEL_CD::STRING,'')) AS dummy_level_cd,\n",
    "            upper(nullif(v:DUMMY_VAR_NAME::STRING,'')) AS dummy_var_name,\n",
    "            nullif(v:DUMMY_COEF::STRING,'')::NUMBER(8,3) AS dummy_coef\n",
    "        FROM dummy_schema.dummy_table AT (TIMESTAMP => '2025-07-31 00:00:00')\n",
    "    ),\n",
    "    get_dummy_data AS (\n",
    "        SELECT\n",
    "            dummy_ver_name,\n",
    "            dummy_pop_name,\n",
    "            dummy_level_cd,\n",
    "            dummy_var_name,\n",
    "            dummy_coef\n",
    "        FROM __dbt__cte__dummy_data\n",
    "    )\n",
    "    SELECT\n",
    "        COALESCE(gd.dummy_ver_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_pop_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_level_cd::VARCHAR, '') || '~' || COALESCE(gd.dummy_var_name::VARCHAR, '') AS dummy_id,\n",
    "        dd.dummy_key,\n",
    "        gd.dummy_ver_name,\n",
    "        gd.dummy_pop_name,\n",
    "        gd.dummy_level_cd,\n",
    "        gd.dummy_var_name,\n",
    "        gd.dummy_coef\n",
    "    FROM get_dummy_data gd\n",
    "    INNER JOIN dummy_schema.dummy_dim dd ON gd.dummy_ver_name = dd.dummy_ver_name\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    physical_tables, cte_names = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    print(\"  Physical tables:\")\n",
    "    for t in physical_tables:\n",
    "        print(f\"    - {t}\")\n",
    "    print(\"  CTE names:\")\n",
    "    for c in cte_names:\n",
    "        print(f\"    - {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2f25c",
   "metadata": {},
   "source": [
    "## Derived/Sub-query example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95601eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries.append(\n",
    "    \"\"\"\n",
    "    WITH __dbt__cte__dummy_data AS (\n",
    "        SELECT\n",
    "            upper(nullif(v:DUMMY_VER_NAME::STRING,'')) AS dummy_ver_name,\n",
    "            upper(nullif(v:DUMMY_POP_NAME::STRING,'')) AS dummy_pop_name,\n",
    "            upper(nullif(v:DUMMY_LEVEL_CD::STRING,'')) AS dummy_level_cd,\n",
    "            upper(nullif(v:DUMMY_VAR_NAME::STRING,'')) AS dummy_var_name,\n",
    "            nullif(v:DUMMY_COEF::STRING,'')::NUMBER(8,3) AS dummy_coef\n",
    "        FROM dummy_schema.dummy_table AT (TIMESTAMP => '2025-07-31 00:00:00')\n",
    "    ),\n",
    "    get_dummy_data AS (\n",
    "        SELECT\n",
    "            dummy_ver_name,\n",
    "            dummy_pop_name,\n",
    "            dummy_level_cd,\n",
    "            dummy_var_name,\n",
    "            dummy_coef\n",
    "        FROM __dbt__cte__dummy_data\n",
    "    )\n",
    "    SELECT\n",
    "        COALESCE(gd.dummy_ver_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_pop_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_level_cd::VARCHAR, '') || '~' || COALESCE(gd.dummy_var_name::VARCHAR, '') AS dummy_id,\n",
    "        gd.dummy_key,\n",
    "        gd.dummy_ver_name,\n",
    "        gd.dummy_pop_name,\n",
    "        gd.dummy_level_cd,\n",
    "        gd.dummy_var_name,\n",
    "        gd.dummy_coef,\n",
    "        sub.latest_status\n",
    "    FROM get_dummy_data gd\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            dummy_ver_name,\n",
    "            MAX(status_date) AS latest_status\n",
    "        FROM dummy_schema.dummy_status\n",
    "        WHERE status_code IN (\n",
    "            SELECT code FROM dummy_schema.status_codes WHERE is_active = 1\n",
    "        )\n",
    "        GROUP BY dummy_ver_name\n",
    "    ) sub ON gd.dummy_ver_name = sub.dummy_ver_name\n",
    "    WHERE gd.dummy_coef > (\n",
    "        SELECT AVG(dummy_coef) FROM dummy_schema.dummy_table WHERE dummy_level_cd = gd.dummy_level_cd\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef5530a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test case 1:\n",
      "  Source/target tables (all physical tables):\n",
      "    - db1.schema1.tableA\n",
      "    - db2.schema2.tableB\n",
      "  CTE names:\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "\n",
      "Test case 2:\n",
      "  Source/target tables (all physical tables):\n",
      "    - analytics.inactive_users\n",
      "    - analytics.orders\n",
      "    - analytics.users\n",
      "  CTE names:\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "    u -> analytics.users\n",
      "    o -> analytics.orders\n",
      "\n",
      "Test case 3:\n",
      "  Source/target tables (all physical tables):\n",
      "    - marketing.leads\n",
      "    - sales.customers\n",
      "    - sales.orders\n",
      "  CTE names:\n",
      "    - recent_orders\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "\n",
      "Test case 4:\n",
      "  Source/target tables (all physical tables):\n",
      "    - crm_db.marketing.leads\n",
      "    - crm_db.sales.customers\n",
      "    - crm_db.sales.orders\n",
      "    - crm_db.sales.products\n",
      "    - crm_db.sales.returns\n",
      "  CTE names:\n",
      "    - active_customers\n",
      "    - recent_orders\n",
      "    - top_products\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "    ac -> active_customers\n",
      "    ro -> recent_orders\n",
      "\n",
      "Test case 5:\n",
      "  Source/target tables (all physical tables):\n",
      "    - dummy_schema.dummy_dim\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "    gd -> get_dummy_data\n",
      "    dd -> dummy_schema.dummy_dim\n",
      "\n",
      "Test case 6:\n",
      "  Source/target tables (all physical tables):\n",
      "    - dummy_schema.dummy_dim\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "  Table aliases:\n",
      "    gd -> get_dummy_data\n",
      "    dd -> dummy_schema.dummy_dim\n",
      "\n",
      "Test case 7:\n",
      "  Source/target tables (all physical tables):\n",
      "    - dummy_schema.dummy_status\n",
      "    - dummy_schema.dummy_table\n",
      "  CTE names:\n",
      "    - __dbt__cte__dummy_data\n",
      "    - get_dummy_data\n",
      "  JOIN/derived subquery tables (valuable for lineage):\n",
      "    - dummy_schema.dummy_status\n",
      "  WHERE subquery tables (not useful for lineage):\n",
      "    - dummy_schema.dummy_table\n",
      "    - dummy_schema.status_codes\n",
      "  Table aliases:\n",
      "    gd -> get_dummy_data\n"
     ]
    }
   ],
   "source": [
    "def extract_snowflake_tables(sql_query):\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    cte_names = set()\n",
    "    table_aliases = dict()\n",
    "    all_physical_tables = set()\n",
    "    join_subquery_tables = set()\n",
    "    where_subquery_tables = set()\n",
    "    cte_source_tables = set()\n",
    "\n",
    "    # Collect CTE names and their source tables\n",
    "    for cte in parsed.find_all(exp.CTE):\n",
    "        if cte.alias:\n",
    "            cte_names.add(cte.alias)\n",
    "        # Find tables referenced inside CTE definitions\n",
    "        for node in cte.find_all(exp.Table):\n",
    "            db = node.catalog or \"\"\n",
    "            schema = node.db or \"\"\n",
    "            name = node.name\n",
    "            if db and schema:\n",
    "                full_name = f\"{db}.{schema}.{name}\"\n",
    "            elif schema:\n",
    "                full_name = f\"{schema}.{name}\"\n",
    "            else:\n",
    "                full_name = name\n",
    "            if full_name not in cte_names:\n",
    "                cte_source_tables.add(full_name)\n",
    "\n",
    "    # Helper to get full table name\n",
    "    def get_full_name(node):\n",
    "        db = node.catalog or \"\"\n",
    "        schema = node.db or \"\"\n",
    "        name = node.name\n",
    "        if db and schema:\n",
    "            return f\"{db}.{schema}.{name}\"\n",
    "        elif schema:\n",
    "            return f\"{schema}.{name}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Collect all physical tables (not CTEs) anywhere in the query\n",
    "    for node in parsed.walk():\n",
    "        if isinstance(node, exp.Table):\n",
    "            full_name = get_full_name(node)\n",
    "            if full_name not in cte_names:\n",
    "                all_physical_tables.add(full_name)\n",
    "            if node.alias:\n",
    "                table_aliases[node.alias] = full_name\n",
    "\n",
    "    # Collect tables in JOIN subqueries and derived tables\n",
    "    for join in parsed.find_all(exp.Join):\n",
    "        for subquery in join.find_all(exp.Subquery):\n",
    "            for node in subquery.walk():\n",
    "                if isinstance(node, exp.Table):\n",
    "                    tbl = get_full_name(node)\n",
    "                    if tbl not in cte_names:\n",
    "                        join_subquery_tables.add(tbl)\n",
    "                    if node.alias:\n",
    "                        table_aliases[node.alias] = tbl\n",
    "\n",
    "    # Collect tables in WHERE subqueries\n",
    "    for where in parsed.find_all(exp.Where):\n",
    "        for subquery in where.find_all(exp.Subquery):\n",
    "            for node in subquery.walk():\n",
    "                if isinstance(node, exp.Table):\n",
    "                    tbl = get_full_name(node)\n",
    "                    if tbl not in cte_names:\n",
    "                        where_subquery_tables.add(tbl)\n",
    "                    if node.alias:\n",
    "                        table_aliases[node.alias] = tbl\n",
    "\n",
    "    valuable_join_tables = sorted(join_subquery_tables - where_subquery_tables)\n",
    "\n",
    "    # Only include as source/target if:\n",
    "    # - referenced in a CTE definition (cte_source_tables)\n",
    "    # - or referenced outside of WHERE subqueries (i.e., not only in where_subquery_tables)\n",
    "    source_target_tables = sorted(\n",
    "        t for t in all_physical_tables\n",
    "        if t in cte_source_tables or t not in where_subquery_tables\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        source_target_tables,\n",
    "        sorted(cte_names),\n",
    "        valuable_join_tables,\n",
    "        sorted(where_subquery_tables),\n",
    "        table_aliases\n",
    "    )\n",
    "\n",
    "# Example usage and test logic:\n",
    "for i, q in enumerate(test_queries, 1):\n",
    "    target_tables, cte_names, join_subquery_tables, where_subquery_tables, table_aliases = extract_snowflake_tables(q)\n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    print(\"  Source/target tables (all physical tables):\")\n",
    "    for t in target_tables:\n",
    "        print(f\"    - {t}\")\n",
    "    print(\"  CTE names:\")\n",
    "    for c in cte_names:\n",
    "        print(f\"    - {c}\")\n",
    "    print(\"  JOIN/derived subquery tables (valuable for lineage):\")\n",
    "    for j in join_subquery_tables:\n",
    "        print(f\"    - {j}\")\n",
    "    print(\"  WHERE subquery tables (not useful for lineage):\")\n",
    "    for w in where_subquery_tables:\n",
    "        print(f\"    - {w}\")\n",
    "    print(\"  Table aliases:\")\n",
    "    for alias, table in table_aliases.items():\n",
    "        print(f\"    {alias} -> {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bbb336",
   "metadata": {},
   "source": [
    "# Columns Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23457fb0",
   "metadata": {},
   "source": [
    "## Aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2427349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_column': 'a', 'expression': 'a', 'source_columns': [('', 'a')], 'type': 'direct'}\n",
      "{'target_column': 'sum_col', 'expression': 'b + c AS sum_col', 'source_columns': [('', 'c'), ('', 'b')], 'type': 'calculated'}\n",
      "{'target_column': 'const_col', 'expression': \"'foo' AS const_col\", 'source_columns': [], 'type': 'constant'}\n",
      "{'target_column': 'd_alias', 'expression': 't1.d AS d_alias', 'source_columns': [('t1', 'd')], 'type': 'calculated'}\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "from sqlglot import expressions as exp\n",
    "\n",
    "def extract_snowflake_columns(sql_query):\n",
    "    \"\"\"\n",
    "    Extracts column lineage information from a Snowflake SQL query.\n",
    "    Returns a list of dicts, each describing an output column.\n",
    "    \"\"\"\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    columns = []\n",
    "\n",
    "    # Helper to get the string representation of an expression\n",
    "    def expr_to_str(expr):\n",
    "        return expr.sql(dialect=\"snowflake\") if expr else None\n",
    "\n",
    "    # Helper to recursively collect all column references in an expression\n",
    "    def collect_source_columns(expr):\n",
    "        sources = set()\n",
    "        for node in expr.walk():\n",
    "            if isinstance(node, exp.Column):\n",
    "                # node.table can be None if unqualified\n",
    "                sources.add((node.table, node.name))\n",
    "        return list(sources)\n",
    "\n",
    "    # Find the outermost SELECT (not inside a subquery)\n",
    "    select = parsed\n",
    "    while not isinstance(select, exp.Select) and select:\n",
    "        select = select.args.get(\"this\") if hasattr(select, \"args\") else None\n",
    "\n",
    "    if not isinstance(select, exp.Select):\n",
    "        # Try to find any SELECT if not top-level\n",
    "        select = next(parsed.find_all(exp.Select), None)\n",
    "\n",
    "    if select:\n",
    "        for proj in select.expressions:\n",
    "            # Target/output column name\n",
    "            alias = proj.alias_or_name\n",
    "            # Raw SQL for the expression\n",
    "            expression_sql = expr_to_str(proj)\n",
    "            # Source columns referenced in the expression\n",
    "            source_columns = collect_source_columns(proj)\n",
    "            # Type: direct, calculated, or constant\n",
    "            if isinstance(proj, exp.Column):\n",
    "                col_type = \"direct\"\n",
    "            elif proj.is_star:\n",
    "                col_type = \"star\"\n",
    "            elif not source_columns:\n",
    "                col_type = \"constant\"\n",
    "            else:\n",
    "                col_type = \"calculated\"\n",
    "            columns.append({\n",
    "                \"target_column\": alias,\n",
    "                \"expression\": expression_sql,\n",
    "                \"source_columns\": source_columns,\n",
    "                \"type\": col_type\n",
    "            })\n",
    "    return columns\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    example_query = \"\"\"\n",
    "    SELECT\n",
    "        a,\n",
    "        b + c AS sum_col,\n",
    "        'foo' AS const_col,\n",
    "        t1.d AS d_alias\n",
    "    FROM my_schema.my_table t1\n",
    "    \"\"\"\n",
    "    cols = extract_snowflake_columns(example_query)\n",
    "    for col in cols:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24920054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source/target tables (all physical tables):\n",
      "  - my_schema.my_table\n",
      "CTE names:\n",
      "Table aliases:\n",
      "  t1 -> my_schema.my_table\n",
      "\n",
      "Columns lineage:\n",
      "Target column: a\n",
      "  Expression: a\n",
      "  Source columns: [('', 'a')]\n",
      "  Resolved source columns: [('', 'a')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: sum_col\n",
      "  Expression: b + c AS sum_col\n",
      "  Source columns: [('', 'c'), ('', 'b')]\n",
      "  Resolved source columns: [('', 'c'), ('', 'b')]\n",
      "  Type: calculated\n",
      "\n",
      "Target column: const_col\n",
      "  Expression: 'foo' AS const_col\n",
      "  Source columns: []\n",
      "  Resolved source columns: []\n",
      "  Type: constant\n",
      "\n",
      "Target column: d_alias\n",
      "  Expression: t1.d AS d_alias\n",
      "  Source columns: [('t1', 'd')]\n",
      "  Resolved source columns: [('my_schema.my_table', 'd')]\n",
      "  Type: calculated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "from sqlglot import expressions as exp\n",
    "\n",
    "def extract_snowflake_tables(sql_query):\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    cte_names = set()\n",
    "    table_aliases = dict()\n",
    "    all_physical_tables = set()\n",
    "    join_subquery_tables = set()\n",
    "    where_subquery_tables = set()\n",
    "    cte_source_tables = set()\n",
    "\n",
    "    # Collect CTE names and their source tables\n",
    "    for cte in parsed.find_all(exp.CTE):\n",
    "        if cte.alias:\n",
    "            cte_names.add(cte.alias)\n",
    "        # Find tables referenced inside CTE definitions\n",
    "        for node in cte.find_all(exp.Table):\n",
    "            db = node.catalog or \"\"\n",
    "            schema = node.db or \"\"\n",
    "            name = node.name\n",
    "            if db and schema:\n",
    "                full_name = f\"{db}.{schema}.{name}\"\n",
    "            elif schema:\n",
    "                full_name = f\"{schema}.{name}\"\n",
    "            else:\n",
    "                full_name = name\n",
    "            if full_name not in cte_names:\n",
    "                cte_source_tables.add(full_name)\n",
    "\n",
    "    # Helper to get full table name\n",
    "    def get_full_name(node):\n",
    "        db = node.catalog or \"\"\n",
    "        schema = node.db or \"\"\n",
    "        name = node.name\n",
    "        if db and schema:\n",
    "            return f\"{db}.{schema}.{name}\"\n",
    "        elif schema:\n",
    "            return f\"{schema}.{name}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Collect all physical tables (not CTEs) anywhere in the query\n",
    "    for node in parsed.walk():\n",
    "        if isinstance(node, exp.Table):\n",
    "            full_name = get_full_name(node)\n",
    "            if full_name not in cte_names:\n",
    "                all_physical_tables.add(full_name)\n",
    "            if node.alias:\n",
    "                table_aliases[node.alias] = full_name\n",
    "\n",
    "    # Collect tables in JOIN subqueries and derived tables\n",
    "    for join in parsed.find_all(exp.Join):\n",
    "        for subquery in join.find_all(exp.Subquery):\n",
    "            for node in subquery.walk():\n",
    "                if isinstance(node, exp.Table):\n",
    "                    tbl = get_full_name(node)\n",
    "                    if tbl not in cte_names:\n",
    "                        join_subquery_tables.add(tbl)\n",
    "                    if node.alias:\n",
    "                        table_aliases[node.alias] = tbl\n",
    "\n",
    "    # Collect tables in WHERE subqueries\n",
    "    for where in parsed.find_all(exp.Where):\n",
    "        for subquery in where.find_all(exp.Subquery):\n",
    "            for node in subquery.walk():\n",
    "                if isinstance(node, exp.Table):\n",
    "                    tbl = get_full_name(node)\n",
    "                    if tbl not in cte_names:\n",
    "                        where_subquery_tables.add(tbl)\n",
    "                    if node.alias:\n",
    "                        table_aliases[node.alias] = tbl\n",
    "\n",
    "    valuable_join_tables = sorted(join_subquery_tables - where_subquery_tables)\n",
    "\n",
    "    # Only include as source/target if:\n",
    "    # - referenced in a CTE definition (cte_source_tables)\n",
    "    # - or referenced outside of WHERE subqueries (i.e., not only in where_subquery_tables)\n",
    "    source_target_tables = sorted(\n",
    "        t for t in all_physical_tables\n",
    "        if t in cte_source_tables or t not in where_subquery_tables\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        source_target_tables,\n",
    "        sorted(cte_names),\n",
    "        valuable_join_tables,\n",
    "        sorted(where_subquery_tables),\n",
    "        table_aliases\n",
    "    )\n",
    "\n",
    "def extract_snowflake_columns(sql_query):\n",
    "    \"\"\"\n",
    "    Extracts column lineage information from a Snowflake SQL query.\n",
    "    Returns a list of dicts, each describing an output column.\n",
    "    \"\"\"\n",
    "    parsed = sqlglot.parse_one(sql_query, dialect=\"snowflake\")\n",
    "    columns = []\n",
    "\n",
    "    # Helper to get the string representation of an expression\n",
    "    def expr_to_str(expr):\n",
    "        return expr.sql(dialect=\"snowflake\") if expr else None\n",
    "\n",
    "    # Helper to recursively collect all column references in an expression\n",
    "    def collect_source_columns(expr):\n",
    "        sources = set()\n",
    "        for node in expr.walk():\n",
    "            if isinstance(node, exp.Column):\n",
    "                # node.table can be None if unqualified\n",
    "                sources.add((node.table, node.name))\n",
    "        return list(sources)\n",
    "\n",
    "    # Find the outermost SELECT (not inside a subquery)\n",
    "    select = parsed\n",
    "    while not isinstance(select, exp.Select) and select:\n",
    "        select = select.args.get(\"this\") if hasattr(select, \"args\") else None\n",
    "\n",
    "    if not isinstance(select, exp.Select):\n",
    "        # Try to find any SELECT if not top-level\n",
    "        select = next(parsed.find_all(exp.Select), None)\n",
    "\n",
    "    if select:\n",
    "        for proj in select.expressions:\n",
    "            # Target/output column name\n",
    "            alias = proj.alias_or_name\n",
    "            # Raw SQL for the expression\n",
    "            expression_sql = expr_to_str(proj)\n",
    "            # Source columns referenced in the expression\n",
    "            source_columns = collect_source_columns(proj)\n",
    "            # Type: direct, calculated, or constant\n",
    "            if isinstance(proj, exp.Column):\n",
    "                col_type = \"direct\"\n",
    "            elif proj.is_star:\n",
    "                col_type = \"star\"\n",
    "            elif not source_columns:\n",
    "                col_type = \"constant\"\n",
    "            else:\n",
    "                col_type = \"calculated\"\n",
    "            columns.append({\n",
    "                \"target_column\": alias,\n",
    "                \"expression\": expression_sql,\n",
    "                \"source_columns\": source_columns,\n",
    "                \"type\": col_type\n",
    "            })\n",
    "    return columns\n",
    "\n",
    "# Example usage and integration:\n",
    "test_sql = \"\"\"\n",
    "SELECT\n",
    "    a,\n",
    "    b + c AS sum_col,\n",
    "    'foo' AS const_col,\n",
    "    t1.d AS d_alias\n",
    "FROM my_schema.my_table t1\n",
    "\"\"\"\n",
    "\n",
    "# Extract tables and aliases\n",
    "tables_result = extract_snowflake_tables(test_sql)\n",
    "source_target_tables, cte_names, join_subquery_tables, where_subquery_tables, table_aliases = tables_result\n",
    "\n",
    "# Extract columns\n",
    "columns_result = extract_snowflake_columns(test_sql)\n",
    "\n",
    "# Resolve source tables for each column using table_aliases\n",
    "for col in columns_result:\n",
    "    resolved_sources = []\n",
    "    for alias, col_name in col[\"source_columns\"]:\n",
    "        if alias in table_aliases:\n",
    "            resolved_sources.append((table_aliases[alias], col_name))\n",
    "        elif alias is None and len(source_target_tables) == 1:\n",
    "            # Unqualified column, only one table in FROM\n",
    "            resolved_sources.append((source_target_tables[0], col_name))\n",
    "        else:\n",
    "            resolved_sources.append((alias, col_name))  # Could be None or a CTE\n",
    "    col[\"resolved_source_columns\"] = resolved_sources\n",
    "\n",
    "# Print results\n",
    "print(\"Source/target tables (all physical tables):\")\n",
    "for t in source_target_tables:\n",
    "    print(f\"  - {t}\")\n",
    "print(\"CTE names:\")\n",
    "for c in cte_names:\n",
    "    print(f\"  - {c}\")\n",
    "print(\"Table aliases:\")\n",
    "for alias, table in table_aliases.items():\n",
    "    print(f\"  {alias} -> {table}\")\n",
    "\n",
    "print(\"\\nColumns lineage:\")\n",
    "for col in columns_result:\n",
    "    print(f\"Target column: {col['target_column']}\")\n",
    "    print(f\"  Expression: {col['expression']}\")\n",
    "    print(f\"  Source columns: {col['source_columns']}\")\n",
    "    print(f\"  Resolved source columns: {col['resolved_source_columns']}\")\n",
    "    print(f\"  Type: {col['type']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10eecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NEW TEST CASE ===\n",
      "All table variables:\n",
      "  source_target_tables: ['dummy_schema.dummy_status', 'dummy_schema.dummy_table']\n",
      "  cte_names: ['__dbt__cte__dummy_data', 'get_dummy_data']\n",
      "  join_subquery_tables: ['dummy_schema.dummy_status']\n",
      "  where_subquery_tables: ['dummy_schema.dummy_table', 'dummy_schema.status_codes']\n",
      "  table_aliases: {'gd': 'get_dummy_data'}\n",
      "\n",
      "Source/target tables (all physical tables):\n",
      "  - dummy_schema.dummy_status\n",
      "  - dummy_schema.dummy_table\n",
      "CTE names:\n",
      "  - __dbt__cte__dummy_data\n",
      "  - get_dummy_data\n",
      "Table aliases:\n",
      "  gd -> get_dummy_data\n",
      "\n",
      "Columns lineage:\n",
      "Target column: dummy_id\n",
      "  Expression: COALESCE(CAST(gd.dummy_ver_name AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_pop_name AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_level_cd AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_var_name AS VARCHAR), '') AS dummy_id\n",
      "  Source columns: [('gd', 'dummy_level_cd'), ('gd', 'dummy_ver_name'), ('gd', 'dummy_pop_name'), ('gd', 'dummy_var_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_level_cd'), ('get_dummy_data', 'dummy_ver_name'), ('get_dummy_data', 'dummy_pop_name'), ('get_dummy_data', 'dummy_var_name')]\n",
      "  Type: calculated\n",
      "\n",
      "Target column: dummy_key\n",
      "  Expression: gd.dummy_key\n",
      "  Source columns: [('gd', 'dummy_key')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_key')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_ver_name\n",
      "  Expression: gd.dummy_ver_name\n",
      "  Source columns: [('gd', 'dummy_ver_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_ver_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_pop_name\n",
      "  Expression: gd.dummy_pop_name\n",
      "  Source columns: [('gd', 'dummy_pop_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_pop_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_level_cd\n",
      "  Expression: gd.dummy_level_cd\n",
      "  Source columns: [('gd', 'dummy_level_cd')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_level_cd')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_var_name\n",
      "  Expression: gd.dummy_var_name\n",
      "  Source columns: [('gd', 'dummy_var_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_var_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_coef\n",
      "  Expression: gd.dummy_coef\n",
      "  Source columns: [('gd', 'dummy_coef')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_coef')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: latest_status\n",
      "  Expression: gd.latest_status\n",
      "  Source columns: [('gd', 'latest_status')]\n",
      "  Resolved source columns: [('get_dummy_data', 'latest_status')]\n",
      "  Type: direct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage and integration:\n",
    "test_sql = \"\"\"\n",
    "SELECT\n",
    "    a,\n",
    "    b + c AS sum_col,\n",
    "    'foo' AS const_col,\n",
    "    t1.d AS d_alias\n",
    "FROM my_schema.my_table t1\n",
    "\"\"\"\n",
    "\n",
    "# Add the complex CTE/subquery example as a test case\n",
    "test_sql_2 = \"\"\"\n",
    "WITH __dbt__cte__dummy_data AS (\n",
    "    SELECT\n",
    "        upper(nullif(v:DUMMY_VER_NAME::STRING,'')) AS dummy_ver_name,\n",
    "        upper(nullif(v:DUMMY_POP_NAME::STRING,'')) AS dummy_pop_name,\n",
    "        upper(nullif(v:DUMMY_LEVEL_CD::STRING,'')) AS dummy_level_cd,\n",
    "        upper(nullif(v:DUMMY_VAR_NAME::STRING,'')) AS dummy_var_name,\n",
    "        nullif(v:DUMMY_COEF::STRING,'')::NUMBER(8,3) AS dummy_coef\n",
    "    FROM dummy_schema.dummy_table AT (TIMESTAMP => '2025-07-31 00:00:00')\n",
    "),\n",
    "get_dummy_data AS (\n",
    "    SELECT\n",
    "        dummy_ver_name,\n",
    "        dummy_pop_name,\n",
    "        dummy_level_cd,\n",
    "        dummy_var_name,\n",
    "        dummy_coef\n",
    "    FROM __dbt__cte__dummy_data\n",
    ")\n",
    "SELECT\n",
    "    COALESCE(gd.dummy_ver_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_pop_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_level_cd::VARCHAR, '') || '~' || COALESCE(gd.dummy_var_name::VARCHAR, '') AS dummy_id,\n",
    "    gd.dummy_key,\n",
    "    gd.dummy_ver_name,\n",
    "    gd.dummy_pop_name,\n",
    "    gd.dummy_level_cd,\n",
    "    gd.dummy_var_name,\n",
    "    gd.dummy_coef,\n",
    "    gd.latest_status\n",
    "FROM get_dummy_data gd\n",
    "INNER JOIN (\n",
    "    SELECT\n",
    "        dummy_ver_name,\n",
    "        MAX(status_date) AS latest_status\n",
    "    FROM dummy_schema.dummy_status\n",
    "    WHERE status_code IN (\n",
    "        SELECT code FROM dummy_schema.status_codes WHERE is_active = 1\n",
    "    )\n",
    "    GROUP BY dummy_ver_name\n",
    ") sub ON gd.dummy_ver_name = sub.dummy_ver_name\n",
    "WHERE gd.dummy_coef > (\n",
    "    SELECT AVG(dummy_coef) FROM dummy_schema.dummy_table WHERE dummy_level_cd = gd.dummy_level_cd\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "for sql in [test_sql_2]:\n",
    "    print(\"\\n=== NEW TEST CASE ===\")\n",
    "    tables_result = extract_snowflake_tables(sql)\n",
    "    source_target_tables, cte_names, join_subquery_tables, where_subquery_tables, table_aliases = tables_result\n",
    "\n",
    "    # --- Add this block to show all table-related variables ---\n",
    "    print(\"All table variables:\")\n",
    "    print(f\"  source_target_tables: {source_target_tables}\")\n",
    "    print(f\"  cte_names: {cte_names}\")\n",
    "    print(f\"  join_subquery_tables: {join_subquery_tables}\")\n",
    "    print(f\"  where_subquery_tables: {where_subquery_tables}\")\n",
    "    print(f\"  table_aliases: {table_aliases}\")\n",
    "    # If you want to see all_physical_tables and cte_source_tables, you need to modify extract_snowflake_tables to return them as well.\n",
    "    # For now, only the above are available from the return value.\n",
    "    print()\n",
    "\n",
    "    columns_result = extract_snowflake_columns(sql)\n",
    "\n",
    "    for col in columns_result:\n",
    "        resolved_sources = []\n",
    "        for alias, col_name in col[\"source_columns\"]:\n",
    "            if alias in table_aliases:\n",
    "                resolved_sources.append((table_aliases[alias], col_name))\n",
    "            elif alias is None and len(source_target_tables) == 1:\n",
    "                resolved_sources.append((source_target_tables[0], col_name))\n",
    "            else:\n",
    "                resolved_sources.append((alias, col_name))\n",
    "        col[\"resolved_source_columns\"] = resolved_sources\n",
    "\n",
    "    print(\"Source/target tables (all physical tables):\")\n",
    "    for t in source_target_tables:\n",
    "        print(f\"  - {t}\")\n",
    "    print(\"CTE names:\")\n",
    "    for c in cte_names:\n",
    "        print(f\"  - {c}\")\n",
    "    print(\"Table aliases:\")\n",
    "    for alias, table in table_aliases.items():\n",
    "        print(f\"  {alias} -> {table}\")\n",
    "\n",
    "    print(\"\\nColumns lineage:\")\n",
    "    for col in columns_result:\n",
    "        print(f\"Target column: {col['target_column']}\")\n",
    "        print(f\"  Expression: {col['expression']}\")\n",
    "        print(f\"  Source columns: {col['source_columns']}\")\n",
    "        print(f\"  Resolved source columns: {col['resolved_source_columns']}\")\n",
    "        print(f\"  Type: {col['type']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0222ed73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NEW TEST CASE ===\n",
      "\n",
      "    WITH __dbt__cte__dummy_data AS (\n",
      "        SELECT\n",
      "            upper(nullif(v:DUMMY_VER_NAME::STRING,'')) AS dummy_ver_name,\n",
      "            upper(nullif(v:DUMMY_POP_NAME::STRING,'')) AS dummy_pop_name,\n",
      "            upper(nullif(v:DUMMY_LEVEL_CD::STRING,'')) AS dummy_level_cd,\n",
      "            upper(nullif(v:DUMMY_VAR_NAME::STRING,'')) AS dummy_var_name,\n",
      "            nullif(v:DUMMY_COEF::STRING,'')::NUMBER(8,3) AS dummy_coef\n",
      "        FROM dummy_schema.dummy_table AT (TIMESTAMP => '2025-07-31 00:00:00')\n",
      "    ),\n",
      "    get_dummy_data AS (\n",
      "        SELECT\n",
      "            dummy_ver_name,\n",
      "            dummy_pop_name,\n",
      "            dummy_level_cd,\n",
      "            dummy_var_name,\n",
      "            dummy_coef\n",
      "        FROM __dbt__cte__dummy_data\n",
      "    )\n",
      "    SELECT\n",
      "        COALESCE(gd.dummy_ver_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_pop_name::VARCHAR, '') || '~' || COALESCE(gd.dummy_level_cd::VARCHAR, '') || '~' || COALESCE(gd.dummy_var_name::VARCHAR, '') AS dummy_id,\n",
      "        gd.dummy_key,\n",
      "        gd.dummy_ver_name,\n",
      "        gd.dummy_pop_name,\n",
      "        gd.dummy_level_cd,\n",
      "        gd.dummy_var_name,\n",
      "        gd.dummy_coef,\n",
      "        sub.latest_status\n",
      "    FROM get_dummy_data gd\n",
      "    INNER JOIN (\n",
      "        SELECT\n",
      "            dummy_ver_name,\n",
      "            MAX(status_date) AS latest_status\n",
      "        FROM dummy_schema.dummy_status\n",
      "        WHERE status_code IN (\n",
      "            SELECT code FROM dummy_schema.status_codes WHERE is_active = 1\n",
      "        )\n",
      "        GROUP BY dummy_ver_name\n",
      "    ) sub ON gd.dummy_ver_name = sub.dummy_ver_name\n",
      "    WHERE gd.dummy_coef > (\n",
      "        SELECT AVG(dummy_coef) FROM dummy_schema.dummy_table WHERE dummy_level_cd = gd.dummy_level_cd\n",
      "    )\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All table variables:\n",
      "  source_target_tables: ['dummy_schema.dummy_status', 'dummy_schema.dummy_table']\n",
      "  cte_names: ['__dbt__cte__dummy_data', 'get_dummy_data']\n",
      "  join_subquery_tables: ['dummy_schema.dummy_status']\n",
      "  where_subquery_tables: ['dummy_schema.dummy_table', 'dummy_schema.status_codes']\n",
      "  table_aliases: {'gd': 'get_dummy_data'}\n",
      "\n",
      "Source/target tables (all physical tables):\n",
      "  - dummy_schema.dummy_status\n",
      "  - dummy_schema.dummy_table\n",
      "CTE names:\n",
      "  - __dbt__cte__dummy_data\n",
      "  - get_dummy_data\n",
      "Table aliases:\n",
      "  gd -> get_dummy_data\n",
      "\n",
      "Columns lineage:\n",
      "Target column: dummy_id\n",
      "  Expression: COALESCE(CAST(gd.dummy_ver_name AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_pop_name AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_level_cd AS VARCHAR), '') || '~' || COALESCE(CAST(gd.dummy_var_name AS VARCHAR), '') AS dummy_id\n",
      "  Source columns: [('gd', 'dummy_level_cd'), ('gd', 'dummy_ver_name'), ('gd', 'dummy_pop_name'), ('gd', 'dummy_var_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_level_cd'), ('get_dummy_data', 'dummy_ver_name'), ('get_dummy_data', 'dummy_pop_name'), ('get_dummy_data', 'dummy_var_name')]\n",
      "  Type: calculated\n",
      "\n",
      "Target column: dummy_key\n",
      "  Expression: gd.dummy_key\n",
      "  Source columns: [('gd', 'dummy_key')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_key')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_ver_name\n",
      "  Expression: gd.dummy_ver_name\n",
      "  Source columns: [('gd', 'dummy_ver_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_ver_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_pop_name\n",
      "  Expression: gd.dummy_pop_name\n",
      "  Source columns: [('gd', 'dummy_pop_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_pop_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_level_cd\n",
      "  Expression: gd.dummy_level_cd\n",
      "  Source columns: [('gd', 'dummy_level_cd')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_level_cd')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_var_name\n",
      "  Expression: gd.dummy_var_name\n",
      "  Source columns: [('gd', 'dummy_var_name')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_var_name')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: dummy_coef\n",
      "  Expression: gd.dummy_coef\n",
      "  Source columns: [('gd', 'dummy_coef')]\n",
      "  Resolved source columns: [('get_dummy_data', 'dummy_coef')]\n",
      "  Type: direct\n",
      "\n",
      "Target column: latest_status\n",
      "  Expression: sub.latest_status\n",
      "  Source columns: [('sub', 'latest_status')]\n",
      "  Resolved source columns: [('sub', 'latest_status')]\n",
      "  Type: direct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sql in test_queries[6:7]:\n",
    "    print(\"\\n=== NEW TEST CASE ===\")\n",
    "    print(sql)\n",
    "    tables_result = extract_snowflake_tables(sql)\n",
    "    source_target_tables, cte_names, join_subquery_tables, where_subquery_tables, table_aliases = tables_result\n",
    "\n",
    "    # --- Add this block to show all table-related variables ---\n",
    "    print(\"All table variables:\")\n",
    "    print(f\"  source_target_tables: {source_target_tables}\")\n",
    "    print(f\"  cte_names: {cte_names}\")\n",
    "    print(f\"  join_subquery_tables: {join_subquery_tables}\")\n",
    "    print(f\"  where_subquery_tables: {where_subquery_tables}\")\n",
    "    print(f\"  table_aliases: {table_aliases}\")\n",
    "    # If you want to see all_physical_tables and cte_source_tables, you need to modify extract_snowflake_tables to return them as well.\n",
    "    # For now, only the above are available from the return value.\n",
    "    print()\n",
    "\n",
    "    columns_result = extract_snowflake_columns(sql)\n",
    "\n",
    "    for col in columns_result:\n",
    "        resolved_sources = []\n",
    "        for alias, col_name in col[\"source_columns\"]:\n",
    "            if alias in table_aliases:\n",
    "                resolved_sources.append((table_aliases[alias], col_name))\n",
    "            elif alias is None and len(source_target_tables) == 1:\n",
    "                resolved_sources.append((source_target_tables[0], col_name))\n",
    "            else:\n",
    "                resolved_sources.append((alias, col_name))\n",
    "        col[\"resolved_source_columns\"] = resolved_sources\n",
    "\n",
    "    print(\"Source/target tables (all physical tables):\")\n",
    "    for t in source_target_tables:\n",
    "        print(f\"  - {t}\")\n",
    "    print(\"CTE names:\")\n",
    "    for c in cte_names:\n",
    "        print(f\"  - {c}\")\n",
    "    print(\"Table aliases:\")\n",
    "    for alias, table in table_aliases.items():\n",
    "        print(f\"  {alias} -> {table}\")\n",
    "\n",
    "    print(\"\\nColumns lineage:\")\n",
    "    for col in columns_result:\n",
    "        print(f\"Target column: {col['target_column']}\")\n",
    "        print(f\"  Expression: {col['expression']}\")\n",
    "        print(f\"  Source columns: {col['source_columns']}\")\n",
    "        print(f\"  Resolved source columns: {col['resolved_source_columns']}\")\n",
    "        print(f\"  Type: {col['type']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6edc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No source column identified because col is coming from 3 tables?\n",
    "# How to align query alias \"sub\" with source table from within derived query? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
